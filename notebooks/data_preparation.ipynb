{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32582c3a-7a4b-4561-b6ee-800255900dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data11 = pd.read_csv('../data/cian_sochi_all1-57_lat.csv')\n",
    "data12 = pd.read_csv('../data/cian_sochi_all58-100_lat.csv')\n",
    "data2 = pd.read_csv('../data/sochi_real_estate_full.csv')\n",
    "\n",
    "data11['date'] = '2025-03-09'\n",
    "data12['date'] = '2025-03-29'\n",
    "\n",
    "data1 = pd.concat([data11, data12], ignore_index=True).drop_duplicates(subset=['url'])\n",
    "\n",
    "data2 = data2.rename(columns={\n",
    "    'geo_lat': 'latitude',\n",
    "    'geo_lon': 'longitude',\n",
    "    'level': 'floor',\n",
    "    'levels': 'floors_count',\n",
    "    'rooms': 'rooms_count',\n",
    "    'area': 'total_meters'\n",
    "})\n",
    "\n",
    "common_cols = list(set(data1.columns) & set(data2.columns))\n",
    "combined = pd.concat([data1[common_cols], data2[common_cols]], ignore_index=True)\n",
    "\n",
    "combined['price'] = pd.to_numeric(combined['price'], errors='coerce')\n",
    "\n",
    "combined['total_meters'] = pd.to_numeric(combined['total_meters'], errors='coerce')\n",
    "combined['latitude'] = pd.to_numeric(combined['latitude'], errors='coerce')\n",
    "combined['longitude'] = pd.to_numeric(combined['longitude'], errors='coerce')\n",
    "combined = combined.dropna().drop_duplicates(subset=['latitude', 'longitude', 'date'])\n",
    "\n",
    "combined['price_per_sqm'] = combined['price'] / combined['total_meters']\n",
    "\n",
    "# we do not want to consider erroneous data\n",
    "min_price = 1000.0\n",
    "\n",
    "# avoiding overly luxurious stuff as outliers\n",
    "max_price = 10000000.0\n",
    "\n",
    "min_livespace = 10.0\n",
    "combined = combined[(combined['price_per_sqm'] > min_price) & (combined['price_per_sqm'] < max_price)]\n",
    "combined = combined[combined['total_meters'] > min_livespace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b17400c-a099-42b0-93d0-13a6a4374880",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b7c17-1a22-4d6e-b5a2-d8b71bcd7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import overpy\n",
    "import os\n",
    "\n",
    "# if not os.path.exists('../data/critical_pois.csv'):\n",
    "if True:\n",
    "    bbox = [43.0, 39.0, 44.0, 40.5]\n",
    "    bbox_str = \",\".join(map(str, bbox))\n",
    "\n",
    "    poi_queries = {\n",
    "        \"school\": f'node[\"amenity\"=\"school\"]({bbox_str});',\n",
    "        \"bus_stop\": f'node[\"highway\"=\"bus_stop\"]({bbox_str});',\n",
    "        \"park\": f'node[\"leisure\"=\"park\"]({bbox_str});',\n",
    "        \"hospital\": f'node[\"amenity\"~\"hospital|clinic\"]({bbox_str});'\n",
    "    }\n",
    "    \n",
    "    api = overpy.Overpass()\n",
    "    # result = api.query(query)\n",
    "\n",
    "    poi_coords = {}\n",
    "\n",
    "    for poi_type, query_template in poi_queries.items():\n",
    "        print(f\"Querying OSM for {poi_type}s...\")\n",
    "        query = f\"\"\"\n",
    "        [out:json][timeout:25];\n",
    "        ({query_template});\n",
    "        out center;\n",
    "        \"\"\"\n",
    "        result = api.query(query)\n",
    "        coords = [(float(node.lat), float(node.lon)) for node in result.nodes if hasattr(node, 'lat')]\n",
    "        poi_coords[poi_type] = coords\n",
    "\n",
    "    print(\"Querying OSM for coastline...\")\n",
    "    coastline_query = f\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    (\n",
    "      way[\"natural\"=\"coastline\"]({bbox_str});\n",
    "    );\n",
    "    (._;>;);\n",
    "    out body;\n",
    "    \"\"\"\n",
    "    result = api.query(coastline_query)\n",
    "\n",
    "    coastline_points = [\n",
    "        (float(node.lat), float(node.lon))\n",
    "        for way in result.ways\n",
    "        for node in way.nodes\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057127f2-58e0-4b30-b9b3-bf80b4844539",
   "metadata": {},
   "source": [
    "## Seeking the closest infrastructure elements (may take some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208a849-1881-4e8b-bad5-63f9940b79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_file = '../data/poi_coords.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a16c41-3180-4307-92e4-f9d20b2a0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_coords['center'] = [(43.57507244238309, 39.78258109486141)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae66e7c-0051-4f2a-8e16-53023e0cb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_coords['sea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c186072-f5f9-4e48-a7ec-a5496aa83891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(serialized_file, 'wb') as f:\n",
    "    pickle.dump(poi_coords, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b601b7-d8ee-490e-9991-a40eb55be758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi = np.radians(lat2 - lat1)\n",
    "    dlambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dphi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "combined_coords = combined[['latitude', 'longitude']].values\n",
    "\n",
    "for poi_type, poi_list in poi_coords.items():\n",
    "    print(f\"Calculating distances to nearest {poi_type}...\")\n",
    "\n",
    "    if not poi_list:\n",
    "        # combined[f'dist_to_{poi_type}_km'] = np.nan\n",
    "        print(f\"Warning: no {poi_type}s were found\")\n",
    "        continue\n",
    "\n",
    "    min_distances = []\n",
    "    for lat, lon in tqdm(combined_coords, desc=f\"Nearest {poi_type}\"):\n",
    "        if np.isnan(lat) or np.isnan(lon):\n",
    "            min_distances.append(None)\n",
    "            continue\n",
    "\n",
    "        dists = [haversine(lat, lon, poi_lat, poi_lon) for poi_lat, poi_lon in poi_list]\n",
    "        min_distances.append(min(dists))\n",
    "\n",
    "    combined[f'dist_to_{poi_type}_km'] = min_distances\n",
    "\n",
    "print(\"Calculating distance to sea...\")\n",
    "dist_to_sea = []\n",
    "for lat, lon in tqdm(combined_coords, desc=\"Distance to sea\"):\n",
    "    if np.isnan(lat) or np.isnan(lon):\n",
    "        dist_to_sea.append(None)\n",
    "        continue\n",
    "    dists = [haversine(lat, lon, sea_lat, sea_lon) for sea_lat, sea_lon in coastline_points]\n",
    "    dist_to_sea.append(min(dists))\n",
    "\n",
    "combined['dist_to_sea_km'] = dist_to_sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee949b68-80df-4cbe-86ba-ced4c0715d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22143914-2185-446a-ab32-27e134268b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage = pd.read_csv('../data/CBR_mortgage_data.csv')\n",
    "\n",
    "# mortgage['Yearly rate (%)'] = mortgage['Yearly rate (%)'].str.replace(',', '.').astype(float)\n",
    "# mortgage['New mortgages'] = mortgage['New mortgages'].str.replace(' ', '').astype(int)\n",
    "# mortgage['New mortgage amount (millions)'] = mortgage['New mortgage amount (millions)'].str.replace(' ', '').astype(float)\n",
    "\n",
    "# mortgage['date'] = pd.to_datetime(\n",
    "#     mortgage['Year'].astype(str) + '-' + mortgage['Month'].astype(str) + '-01',\n",
    "#     format='%Y-%m-%d'\n",
    "# )\n",
    "\n",
    "# mortgage = mortgage[['date', 'Yearly rate (%)', 'New mortgages', 'New mortgage amount (millions)']]\n",
    "# mortage = mortgage.sort_values('date')\n",
    "# mortage.to_csv('../data/CBR_mortgage_data.csv', index=False)\n",
    "mortgage['inflation_multiplier'] = (1 + mortgage['Yearly rate (%)'] / 1200).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2daae6-5d60-4e0d-b0e0-ae981e39156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90369c-d16f-4935-83e6-44279d0fa871",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['date'] = pd.to_datetime(combined['date'])\n",
    "\n",
    "merged = pd.merge_asof(\n",
    "    combined.sort_values('date'),\n",
    "    mortgage.sort_values('date'),\n",
    "    on='date',\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "merged['price_inflation_adjusted'] = merged['price'] / merged['inflation_multiplier']\n",
    "merged['price_per_sqm_adjusted'] = merged['price_per_sqm'] / merged['inflation_multiplier']\n",
    "\n",
    "merged = merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bda1af-c127-47ec-b99b-af2b8d755ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "geo_features = merged[['latitude', 'longitude', 'log_price_per_sqm']]\n",
    "geo_scaled = scaler.fit_transform(geo_features)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42).fit(geo_scaled)\n",
    "merged['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec3f6b5-2189-43e8-a4d5-29e39be7a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc4f16-c393-473e-b51c-9328d7f40dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../data/main_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
